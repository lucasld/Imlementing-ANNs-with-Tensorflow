{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea575432-8559-47ae-80f3-6268896a2c71",
   "metadata": {},
   "source": [
    "# Homework 07\n",
    "This weeks task is to implement a LSTM (Long short-term memory) network. To test our implementation we will predict if the integral of some given noise sequence is positive of negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2038fad4-17e3-468b-884a-0df01221264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "from training import training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296088f1",
   "metadata": {},
   "source": [
    "## 1. Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2803fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 8\n",
    "DATASET_LENGTH = 10_000\n",
    "def integration_task(seq_len, num_samples):\n",
    "    for _ in range(num_samples):\n",
    "        x = tf.random.normal((seq_len,1))\n",
    "        y = tf.expand_dims(tf.cast(tf.math.reduce_sum(x) > 0, tf.int16), -1)\n",
    "        #Y = np.expand_dims(int(tf.math.reduce_sum(x) == 1), -1) # why == 1? will never be true\n",
    "        yield x, y\n",
    "\n",
    "\n",
    "def my_integration_task():\n",
    "    for x,y in integration_task(SEQUENCE_LENGTH, DATASET_LENGTH):\n",
    "        yield x, y\n",
    "\n",
    "data = tf.data.Dataset.from_generator(\n",
    "    my_integration_task,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(SEQUENCE_LENGTH,1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(1,), dtype=tf.int16))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a326246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(data, batch_size) -> tf.data:\n",
    "    \"\"\"Apply preproccesing pipeline to the given dataset.\n",
    "    \n",
    "    :param data: data to be preprocessed\n",
    "    :type data: tensorflow 'Dataset'\n",
    "    :param means_array: array of the same shape as an image, containing every\n",
    "        feature's mean over all images in the train dataset\n",
    "    :type means_array: numpy array of floats\n",
    "    :param std_array: array of the same shape as an image, containing every\n",
    "        feature's standart deviation over all images in the train dataset\n",
    "    :type std_array: numpy array of floats\n",
    "    :param batch_size: batch size of the created dataset\n",
    "    :type batch_size: integer\n",
    "    :return: preprocessed dataset\n",
    "    :rtype: tensorflow 'Dataset'\n",
    "    \"\"\"\n",
    "    # cache the dataset\n",
    "    data = data.cache()\n",
    "    # shuffle, batch and prefetch the dataset\n",
    "    data = data.shuffle(1000)\n",
    "    data = data.batch(batch_size)\n",
    "    data = data.prefetch(100)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_dataset(ds, split_proportions = {\n",
    "    'train': 0.7,\n",
    "    'valid': 0.1,\n",
    "    'test': 0.2}):\n",
    "    assert sum(split_proportions.values()) <= 1,\\\n",
    "        \"The sum of split_proportions is larger than 1!\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382741af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 8 1], shape=(3,), dtype=int32) tf.Tensor([5 1], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "datasets = {\n",
    "    'train': ,\n",
    "    'valid': valid_ds,\n",
    "    'test': test_ds\n",
    "}\n",
    "\n",
    "datasets = {key:preprocessing_pipeline(ds, BATCH_SIZE) for key, ds in datasets.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4953ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Cell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, unit_forget_bias=True) -> None:\n",
    "        \"\"\"Constructor function\"\"\"\n",
    "        super(LSTM_Cell, self).__init__()\n",
    "        self.units = units\n",
    "        # forget gate\n",
    "        self.fg_layer = tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation='sigmoid',\n",
    "            bias_initializer='ones' if unit_forget_bias else 'glorot_uniform'\n",
    "        )\n",
    "        # input gate\n",
    "        self.ig_layer = self.fg_W = tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation='sigmoid'\n",
    "        )\n",
    "        # output gate\n",
    "        self.og_layer = self.fg_W = tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation='sigmoid'\n",
    "        )\n",
    "        # cell\n",
    "        self.cell_layer = self.fg_W = tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation='tanh'\n",
    "        )\n",
    "    \n",
    "\n",
    "    def call(self, x, states) -> Tuple[tf.Tensor]: \n",
    "        prev_hidden_state, prev_cell_state = states\n",
    "        # gate inputs\n",
    "        xh = tf.concat([x, prev_hidden_state], axis=1)\n",
    "        # forget gate output\n",
    "        ffilter = self.fg_layer(xh)\n",
    "        # input gate output\n",
    "        ifilter = self.ig_layer(xh)\n",
    "        # cell state candidates\n",
    "        cs_cand = self.cell_layer(xh)\n",
    "        # update cell state\n",
    "        cell_state = tf.math.multiply(ffilter, prev_cell_state) +\\\n",
    "                     tf.math.multiply(ifilter, cs_cand)\n",
    "        # output gate output\n",
    "        ofilter = self.og_layer(xh)\n",
    "        # new hidden state\n",
    "        hidden_state = tf.math.multiply(ofilter, tf.nn.tanh(cell_state))\n",
    "        return hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc771504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, cells) -> None:\n",
    "        super(LSTM_Layer, self).__init__()\n",
    "        self.cells = cells\n",
    "    \n",
    "    #@tf.function\n",
    "    def call(self, x, states=None) -> tf.Tensor:\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        sequence_length = tf.shape(x)[1]\n",
    "        if not states:\n",
    "            states = self.zero_states(batch_size)\n",
    "        output_sequence = []\n",
    "        # iterate through time steps in input sequence\n",
    "        for c_i, cell in enumerate(self.cells):\n",
    "            cell_state = (states[0][:, c_i, :], states[1][:, c_i, :]) \n",
    "            cell_state_agg = []\n",
    "            for seq_idx in range(sequence_length):\n",
    "                input = x[:,seq_idx,:]\n",
    "                cell_state = cell(input, cell_state)\n",
    "                cell_state_agg.append(cell_state[0])\n",
    "            output_sequence.append(cell_state_agg)\n",
    "        # rearange output sequence\n",
    "        output_sequence = tf.transpose(output_sequence, perm=[2, 1, 0, 3])\n",
    "        # concat outputs from all lstm-cells\n",
    "        #print(output_sequence)\n",
    "        os_shape = tf.shape(output_sequence)\n",
    "        output_sequence = tf.reshape(output_sequence, (os_shape[0],\n",
    "                                                       os_shape[1],\n",
    "                                                       os_shape[2]*os_shape[3])\n",
    "                                    )\n",
    "        return output_sequence\n",
    "    \n",
    "    def zero_states(self, batch_size):\n",
    "        return (tf.zeros((batch_size, len(self.cells), self.cells[0].units)),\n",
    "                tf.zeros((batch_size, len(self.cells), self.cells[0].units)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2d879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_list=[\n",
    "        tf.keras.layers.Dense(5, activation='sigmoid'),\n",
    "        LSTM_Layer(cells=[LSTM_Cell(6)]),\n",
    "        tf.keras.layers.Dense(3, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(1, activation='relu')\n",
    "    ]) -> None:\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.layer_list = layer_list\n",
    "    \n",
    "    def call(self, x):\n",
    "        input = x\n",
    "        for layer in self.layer_list:\n",
    "            input = layer(input)\n",
    "        return input[:,-1,:]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ff6469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "100\n",
      "0\n",
      "100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ac2b7f74dd9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m losses, accuracies = training(LSTM_Model(), datasets,\n\u001b[1;32m     16\u001b[0m                               \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                               optimizer, epochs=10)\n\u001b[0m",
      "\u001b[0;32m~/Documents/stud/WISE 2021:2022/ANN in Tensorflow/homeworks/homework 07/training.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(input_model, datasets, loss_function, optimizer, epochs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# Train-Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/stud/WISE 2021:2022/ANN in Tensorflow/homeworks/homework 07/training.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_data, loss_function)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_max_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# add loss and accuracy to aggregators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    143\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m   return backend.mean(\n\u001b[0;32m-> 1807\u001b[0;31m       \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m       axis=axis)\n\u001b[1;32m   1809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   5173\u001b[0m   \u001b[0mbce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5174\u001b[0m   \u001b[0mbce\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mneg\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   6748\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6749\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 6750\u001b[0;31m         _ctx, \"Neg\", name, x)\n\u001b[0m\u001b[1;32m   6751\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6752\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(len(list(dataset)))\n",
    "train = dataset.take(100)\n",
    "test = dataset.skip(100)\n",
    "valid = test.skip(100)\n",
    "test = test.take(100)\n",
    "datasets = {'train':train, 'valid':valid, 'test':test}\n",
    "print(len(list(datasets['train'])))\n",
    "print(len(list(datasets['valid'])))\n",
    "print(len(list(datasets['test'])))\n",
    "# Initialize the loss-function\n",
    "cross_entropy_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# Initialize the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(0.001)\n",
    "\n",
    "losses, accuracies = training(LSTM_Model(), datasets,\n",
    "                              cross_entropy_loss,\n",
    "                              optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bafe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.865401  ]\n",
      "  [-0.07156665]\n",
      "  [-0.942625  ]\n",
      "  [ 0.34527218]\n",
      "  [-0.8537018 ]\n",
      "  [-1.4697397 ]\n",
      "  [ 0.914009  ]\n",
      "  [ 1.051807  ]]\n",
      "\n",
      " [[-0.76230496]\n",
      "  [-0.09492179]\n",
      "  [ 0.19700608]\n",
      "  [-0.8741309 ]\n",
      "  [ 1.3292289 ]\n",
      "  [ 2.191437  ]\n",
      "  [ 0.6160504 ]\n",
      "  [-0.5027481 ]]\n",
      "\n",
      " [[-1.4027071 ]\n",
      "  [ 0.62084323]\n",
      "  [ 2.0610416 ]\n",
      "  [-0.09388001]\n",
      "  [-0.73883116]\n",
      "  [-0.04252322]\n",
      "  [-0.5677695 ]\n",
      "  [ 1.3584127 ]]\n",
      "\n",
      " [[ 0.92604935]\n",
      "  [ 0.89551175]\n",
      "  [ 0.48916686]\n",
      "  [-0.22881404]\n",
      "  [ 0.3331596 ]\n",
      "  [-0.22380687]\n",
      "  [ 0.3951474 ]\n",
      "  [-1.6837456 ]]], shape=(4, 8, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.33760962]\n",
      "  [0.5139302 ]\n",
      "  [0.6757057 ]\n",
      "  [0.4331786 ]\n",
      "  [0.66034985]\n",
      "  [0.7585263 ]\n",
      "  [0.32919678]\n",
      "  [0.30594712]]\n",
      "\n",
      " [[0.64420784]\n",
      "  [0.5184726 ]\n",
      "  [0.46171853]\n",
      "  [0.6639091 ]\n",
      "  [0.26207936]\n",
      "  [0.15359649]\n",
      "  [0.38230568]\n",
      "  [0.5966521 ]]\n",
      "\n",
      " [[0.7488358 ]\n",
      "  [0.3814246 ]\n",
      "  [0.16726774]\n",
      "  [0.51827   ]\n",
      "  [0.6400068 ]\n",
      "  [0.50827837]\n",
      "  [0.6087766 ]\n",
      "  [0.25770772]]\n",
      "\n",
      " [[0.32712942]\n",
      "  [0.33238566]\n",
      "  [0.40589592]\n",
      "  [0.5444319 ]\n",
      "  [0.4354962 ]\n",
      "  [0.5434646 ]\n",
      "  [0.42366734]\n",
      "  [0.7877277 ]]], shape=(4, 8, 1), dtype=float32)\n",
      "[array([[-0.77878904]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM_Layer([LSTM_Cell(3), LSTM_Cell(3), LSTM_Cell(3), LSTM_Cell(3)])\n",
    "dlayer = tf.keras.layers.Dense(1,'sigmoid')\n",
    "for input, _ in dataset.take(1):\n",
    "    print(input)\n",
    "    print(dlayer(input))\n",
    "    #output = lstm.call(input, None)\n",
    "print(dlayer.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adef31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([0., 1., 1., 2., 3., 5., 8.], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def fibonacci(n):\n",
    "  ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "  ta = ta.unstack([0., 1.])\n",
    "\n",
    "  for i in range(2, n):\n",
    "    ta = ta.write(i, ta.read(i - 1) + ta.read(i - 2))\n",
    "\n",
    "  return ta.stack()\n",
    "\n",
    "fibonacci(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f70f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3049741 ,  0.02408729, -0.68296275,  0.2989081 , -0.36264464,\n",
       "       -0.89054254,  1.37596087,  0.00981885,  0.66994094, -0.61534579])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_w = np.random.normal(size=(4,10))\n",
    "fg_b = np.ones((10, 1))\n",
    "x = np.random.rand(4)\n",
    "\n",
    "x @ fg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e4971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
